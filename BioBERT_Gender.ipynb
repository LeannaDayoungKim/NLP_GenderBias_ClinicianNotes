{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BioBERT on Clinical Trial Notes \n",
    "## To check gender bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "warnings.filterwarnings(action='ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "#tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import re\n",
    "import pickle\n",
    "\n",
    "import codecs\n",
    "from tqdm import tqdm\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as keras\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from keras import Input, Model\n",
    "from keras import optimizers\n",
    "from keras.layers import Lambda\n",
    "\n",
    "from keras_bert import load_trained_model_from_checkpoint, load_vocabulary\n",
    "from keras_bert import Tokenizer\n",
    "from keras_bert import AdamWarmup, calc_train_steps\n",
    "\n",
    "from keras_radam import RAdam # import revised version of Adam optimizer, keras-adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse('./train/100.xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PatientMatching',\n",
       " 'TEXT',\n",
       " 'TAGS',\n",
       " 'ABDOMINAL',\n",
       " 'ADVANCED-CAD',\n",
       " 'ALCOHOL-ABUSE',\n",
       " 'ASP-FOR-MI',\n",
       " 'CREATININE',\n",
       " 'DIETSUPP-2MOS',\n",
       " 'DRUG-ABUSE',\n",
       " 'ENGLISH',\n",
       " 'HBA1C',\n",
       " 'KETO-1YR',\n",
       " 'MAJOR-DIABETES',\n",
       " 'MAKES-DECISIONS',\n",
       " 'MI-6MOS']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[elem.tag for elem in root.iter()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Datasets\n",
    "<b> we would retreive the data under 'TEXT' tag, which is clinician notes.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Record date: 2106-02-12\n",
      "\n",
      "Campbell Orthopedic Associates\n",
      "4 Madera Circle\n",
      "Omak, GA 28172\n",
      " \n",
      "Habib Valenzuela, M.D.\n",
      " \n",
      " \n",
      "                                             Valdez, Harlan Jr.  \n",
      "                                           845-41-54-4\n",
      "                                             February 12, 2106 \n",
      "Har is a 43 year old 6' 214 pound gentleman who is referred for\n",
      "consultation by Dr. Harlan Oneil.  About a week ago he slipped on\n",
      "the driveway at home and sustained an injury to his left ankle. \n",
      "He was seen at Tri-City Hospital and was told he had a\n",
      "fracture.  He was placed in an air splint and advised to be\n",
      "partial weight bearing, and he is using a cane.  He is here for\n",
      "routine follow-up. \n",
      "Past medical history is notable for no ankle injuries previously. \n",
      "He has a history of diabetes and sleep apnea.  He takes Prozac,\n",
      "Cardizem, Glucophage and Amaryl.  He is also followed by Dr. Harold\n",
      "Nutter for an arrhythmia.  He does not smoke.  He drinks\n",
      "minimally.  He is a set designer at Columbia Pictures.\n",
      " \n",
      "On examination today he has slight tenderness of the left ankle\n",
      "about four fingerbreadths above the malleolus.  The malleolus is\n",
      "non-tender medially or laterally with no ligamentous tenderness\n",
      "either.  Dorsal flexion and plantar flexion is without pain. \n",
      "There is no significant swelling.  There are no some skin changes\n",
      "with some small abrasions proximally.  There is no fibular\n",
      "tenderness proximally.  No anterior pain is noted.  No hindfoot,\n",
      "midfoot or forefoot tenderness is noted. \n",
      "I would like him to use a tube sock with his air cast.  He is\n",
      "using a cane for ambulation.  His x-rays do not show a notable\n",
      "fracture pattern today, and we will await the Radiology opinion. \n",
      "I would like him to stay in the air splint with the sock.  I will\n",
      "see him back in six weeks for review at the Boxborough office. \n",
      " \n",
      " \n",
      "Diagnosis:  Left ankle fracture.\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "__________________________________________\n",
      "Habib Valenzuela, M.D.\n",
      " \n",
      "HV/kuntz\n",
      "Mmedical\n",
      " \n",
      "cc:  Harlan Oneil, M.D.\n",
      "     \n",
      "     Harold Nutter, M.D.\n",
      "     Doctors Hospital North\n",
      "     64 Bruce St\n",
      "     Omak, GA 72196\n",
      " \n",
      "Habib Valenzuela, M.D.\n",
      " \n",
      "DD: 02/12/06\n",
      "DT: 02/17/06\n",
      "DV: 02/12/06\n",
      " ******** Not reviewed by Attending Physician ********\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Record date: 2108-03-14\n",
      "\n",
      "                     CAMPBELL EMERGENCY DEPT VISIT\n",
      "\n",
      " \n",
      "\n",
      "VALDEZ,HARLAN,JR.   845-41-54-4                VISIT DATE: 03/14/08\n",
      "\n",
      "The patient was seen and examined in the emergency department.  The \n",
      "\n",
      "patient was seen by the Emergency Medicine resident.  I have \n",
      "\n",
      "discussed the management with the resident.  I have also seen the \n",
      "\n",
      "patient primarily and reviewed the medical record.  This is a brief \n",
      "\n",
      "addendum to the medical record.\n",
      "\n",
      "HISTORY OF PRESENTING COMPLAINT:  Briefly, this is a 45-year-old \n",
      "\n",
      "male who complains of several days of nausea, vomiting, and left \n",
      "\n",
      "lower quadrant discomfort.  He also describes intermittent chest \n",
      "\n",
      "pain, which he has had for a number of months without significant \n",
      "\n",
      "change.  He was sent in from his primary care doctor today with \n",
      "\n",
      "this pain and was also noted to have some EKG changes.  The patient \n",
      "\n",
      "has no chest pain at the time of evaluation in the emergency \n",
      "\n",
      "department and no shortness of breath.\n",
      "\n",
      "REVIEW OF SYSTEMS:  As indicated and otherwise negative.\n",
      "\n",
      "PAST MEDICAL HISTORY:  As indicated in the chart.\n",
      "\n",
      "SOCIAL HISTORY AND FAMILY HISTORY:  As indicated in the chart.\n",
      "\n",
      "PHYSICAL EXAMINATION:  On physical examination, the patient is very \n",
      "\n",
      "well-appearing, a smiling, very pleasant gentleman in no acute \n",
      "\n",
      "distress.  The blood pressure is 119/90, the pulse 82, and the \n",
      "\n",
      "temperature 97.9 degrees.  Normocephalic and atraumatic.  The chest \n",
      "\n",
      "is clear to auscultation.  The heart has a regular rate and rhythm. \n",
      "\n",
      "The abdomen is soft.  He has left lower quadrant tenderness.  He \n",
      "\n",
      "also, of note on cardiovascular examination, has a soft murmur \n",
      "\n",
      "which he says he has had since childhood.  The extremities are \n",
      "\n",
      "normal.  The neurologic examination is non-focal. \n",
      "\n",
      "THERAPY RENDERED/COURSE IN ED:  This is a gentleman with abdominal \n",
      "\n",
      "pain who will receive a CAT scan to rule out diverticulitis.  He \n",
      "\n",
      "has also had some non-specific ST changes on his EKG.  He is \n",
      "\n",
      "pain-free at this time.  He does not describe a classic exertional \n",
      "\n",
      "pattern for his chest pain, but given that he is a diabetic and \n",
      "\n",
      "with EKG changes, he will also be admitted for rule out MI.  A CT \n",
      "\n",
      "is pending at the time of this dictation.\n",
      "\n",
      "DISPOSITION (including condition upon discharge):  As above.  The \n",
      "\n",
      "patient's condition is currently stable. \n",
      "\n",
      "___________________________________                    CK498/89095 \n",
      "\n",
      "JAY CARROLL, M.D.  JC72                                 D:03/14/08 \n",
      "\n",
      "                                                       T:03/14/08 \n",
      "\n",
      "Dictated by:  JAY CARROLL, M.D.  JC72 \n",
      "\n",
      " ******** Not reviewed by Attending Physician ********\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Record date: 2109-09-14\n",
      "\n",
      " \n",
      "September 14, 2109 \n",
      " \n",
      "Vicente Blair, M.D.  \n",
      "Internal Medical \n",
      "Doctors Hospital North \n",
      "Omak, Georgia 72196 \n",
      " \n",
      "RE: VALDEZ, Harlan \n",
      "DHN#: 7672624 \n",
      "DATE OF BIRTH: 11/09/2062 \n",
      "CURRENT CLINIC VISIT DATE: 09/14/2109 \n",
      " \n",
      "Dear Vicente, \n",
      " \n",
      "Thank you in advance for allowing me to share in the medical care of Mr. Harlan B. Valdez, a 46-year-old male patient with prior polysomnographic evidence of sleep disordered breathing, as well as a history of difficulty in sleep, reinitiation and maintenance and increased early morning awakenings, as well as mixed systemic medical conditions.  \n",
      " \n",
      "HISTORY OF PRESENT ILLNESS: As you already know, Mr. Valdez who demonstrates a history of difficulties of sleep reinitiation and maintenance, as well as increased early morning awakenings, has noted an exacerbation of these sleep difficulties, occurring in temporal association with his loss of his wife from pancreatic cancer last year. He is now placed in the unfortunate situation of being a single parent to a 15-year-old son and a 10-year-old daughter and describes a modification of his current employment duties of a set designer. In particular, Mr. Valdez describes undergoing on frequent international travelling which has bee markedly curtailed as he is tending to his family situation closer to home.  \n",
      " \n",
      "He described a history of intermittent snoring symptomatology but is unaware of specific nocturnal respiratory pauses. He is unaware of a \"restless\" lower limb sensory complaints which may impact on his ability to initiate or reinitiate sleep. He denies a history of a \" night owl\" personality or circadian rhythm dysfunction which may have played a role with respect to nocturnal sleep disruptions or sleep difficulties.   \n",
      "He denies a history of paroxysmal abnormal disturbances or associated narcoleptic symptoms.  \n",
      " \n",
      "Mr. Valdez underwent an initial formal polysomnographic evaluation at the center for sleep diagnostics at Holy Cross on 11/26/05, during which time he was noted to demonstrate a respiratory disturbance index of 81/hour, particularly exacerbated in the supine position and characterized predominantly by hypopneas, with equal distribution during non-REM and stage REM sleep and with associated O2 desaturation Nadir of 88% The respiratory disturbances were predominantly obstructive or mixed hypopneas. In addition, loud snoring was noted.  \n",
      " \n",
      "There was evidence of a sleep efficiency of 88% and a short sleep onset latency of 4 minutes. There was a predominance of \"light\" non-REM stages I-II sleep, and a concomitant inability to achieve significant \"slow-wave\" or stage REM sleep. There was also \"alpha intrusions and alpha delta sleep\" evident during the initial sleep study. In addition premature ventricular contractions were noted.  \n",
      " \n",
      "The patient underwent a CPAP titration on 01/15/06, also at the Tenacre Foundation Nursing Home in Boxborough, during which time there was a marked reduction in the frequency of hypopneas (respiratory disturbance index equals 2/hour) with CPAP titrations between 4-6 cm. Sleep efficiency improved to 91%, a short sleep onset latency was also noted (3 minutes). There was once again an increased predominance of \"light\" non-REM stage I-II sleep, with concomitant inability to achieve sustained \"slow wave sleep\".  \n",
      " \n",
      "Since his initial trial of nocturnal CPAP titration (at 6 cm of water pressure) and with various CPAP mask modifications (including CPAP nasal face mask and a Mallinckrodt \"Breeze\" supportive head gear with \"nasal pillows\". The patient describes associated claustrophobic symptomatology, relative difficulties with sustained nocturnal home CPAP use, and difficulties with regards to CPAP to being and complications by the bulkiness of the CPAP machine in general. As a result, he has not utilized nocturnal CPAP therapy for a period of time, although he still maintains the CPAP equipment in his house.  \n",
      " \n",
      "Of particular note, and exacerbation of the past year, the patient demonstrates increased early morning awakenings (averaging 2-4 in number) with typical awakenings occurring approximately two hours after sleep initiation at 9:30 p.m. (the patient describes one awakening at 11:30 p.m. and the second awakening at 11:45 a.m., of unclear causative etiology). The patient then might awaken at 3 a.m. and be \"ready for the day\".  If he is able to reinitiate sleep thereafter, the patient may demonstrate additional two early morning awakenings after a final awakening at 6 a.m.  \n",
      " \n",
      "The patient is noted to have a history of mixed systemic conditions including diabetes, coronary artery disease, depressive disorder, as well as a relatively stable gastrointestinal condition, with no upper GI evidence of gastroparesis.  \n",
      " \n",
      "MEDICATIONS:  \n",
      "1. Provigil 200 mg p.o. q. a.m. PRN.  \n",
      "2. Lithium.  \n",
      "3. Valproate.  \n",
      "4. Glucophage 850 mg t.i.d.  \n",
      "5. Humulin 15 units at night.  \n",
      "6. Folate.  \n",
      "7. Metoprolol.  \n",
      "8. Cardia.  \n",
      "9. Vitamin E.  \n",
      "10. Coated aspirin.  \n",
      " \n",
      "ALLERGIES/ADVERSE REACTIONS: The patient describes an enhancement to suicidal tendencies in association with prior Prozac usage.   \n",
      "SOCIAL HISTORY: The patient denies active tobacco or alcoholic beverage usage. He has lost 15-20 pounds over the past several years. His current weight is 195 pounds. He is desirous of losing some additional weight with regards to more regular exercise, but his hectic social situation makes this somewhat difficult at the present time.  \n",
      " \n",
      "On examination, the patient demonstrates a blood pressure of 146/88, (seated, left arm), respiratory rate 16.  \n",
      " \n",
      "HEENT EXAMINATION: Borderline small posterior oropharyngeal aperture, with slightly increased redundant tissue evident posteriorly and a slightly elongated uvula noted.  \n",
      " \n",
      "The patient appears awake, alert, with speech clear and fluent and receptive language function essentially intact. He is presently wearing dental braces. No obvious cranial nerve deficits are appreciated. No focal, sensory, motor or neurologic deficits are noted. No significant appendicular dystaxias or dysmetrias are currently in evidence. The routine gait appears to be normal based, without evidence of significant gait dystaxias.  No current clinical ictal manifestations are present. No acute evidence of \"micro-sleeps\" are noted.  \n",
      " \n",
      "IMPRESSION:  \n",
      "1. Sleep stage/arrousal dysfunction (780.56): Manifested by subjective complaints of nonrestorative sleep, increased daytime fatigue and alternating hypersomnia, and recurrent polysomnographic evidence of \"lightened\" sleep pattern, with increased predominance of non-REM stages 1-2 sleep, and with the presence of \"alpha\" intrusions and \"alpha delta\" component to deeper sleep. These latter EEG findings have been described in association with subjective complaints of nonrestorative sleep, as well as clinical setting of chronic pain related complaints, depressive or anxiety disorder or intercurrent psychotropics agents used (but more usually associated with benzodiazepine or barbituate usage).  \n",
      "2. Sleep disordered breathing: As evidenced during prior polysomnographic evaluations, mostly of obstructive and or mixed hypopnea. The patient appears largely refractory to a trial of CPAP therapy, particularly in so far as he demonstrates associated claustrophobic symptoms in association with it's usage, despite relatively modest CPAP water pressures (6 cm). In addition, he has tried various nasal CPAP face mask, including the Mallinckrodt \"Breeze\" supportive head gear with \"nasal pillows\" and with limited success. One might consider repeating a polysomnographic evaluation in the future, and if so, utilizing a potential trial of BIPAP titration, which may help to improve claustrophobic symptoms, but the patient will still be left with the issues referable to \"tangled tubing at night\" and issues referable to nasal face mask usage, as noted above.  3. Relative difficulties in sleep reinitiation and maintenance:  The patient describes at least 2-4 early morning awakenings with difficulty in sleep reinitiation and maintenance, thereby compounding his current sleep problem. While there would logically be a relationship between his current sleep exacerbations and the recent death of his wife from pancreatic cancer last year, there may also be evidence of other nocturnal sleep disturbances for which a repeat polysomnographic evaluation; i.e. in particular looking for the presence of increased spontaneous arousals or limb associated arousals or periodic limb movements of sleep may be of a special clinical benefit.  \n",
      " \n",
      "PLAN:  \n",
      "1. In the short course, in so far as the patient describes himself as being exceedingly tired, and unable to perform the routine daily tasks of work and managing a family in the absence of his deceased wife, I have suggested initiation of PRN Zolpidem tartrate therapy, 5 mg tablets, utilizing one to two tablets p.o.  q. h.s. PRN for difficulties of sleep reinitiation and maintenance.  \n",
      "2. The patient is advised to take Zolpidem tartrate therapy no more than 2-3 times per week, in an effort to avoid any issues of physiologic dependency.  \n",
      "3. The patient was advised against potential adverse behavioral and or systemic side effects of Zolpidem tartrate therapy including  hypersomnolence, gastric upset, loose stools, diarrhea, and or cardiac palpitations.  \n",
      "Pending his clinical response of his Zolpidem tartrate therapy, I then might seek direct treatment for his sleep disordered breathing issues which may include a repeat sleep study with potential trial of BIPAP therapy (in an effort to modify or attenuate claustrophobic symptoms). If he proves poorly responsive to trial of BIPAP therapy however, I might consider supplemental O2 therapy at night and, with this in mind a follow up sleep study should have associated end-tidal CO2 monitoring as well.  \n",
      "4. In the meantime, the patient was advised to contact the sleep disorders clinic for any acute sleep related concerns in the interim.  \n",
      "5. The patient may also benefit from nonpharmacologic approaches with regards to sleep reinitiation such as hypnotherapy, but I will hold off on these strategies pending follow up sleep disorders clinic evaluation (in approximately four months time).   \n",
      "Once again, thank you again for allowing me to share in the medical care of Mr. Harlan Valdez. I hope this letter finds you well.  \n",
      " \n",
      "Sincerely yours, \n",
      " \n",
      " \n",
      "Yovani Vergara, M.D.  \n",
      "Sleep Clinic \n",
      "Doctors Hospital North \n",
      " \n",
      " \n",
      "cc: Sleep Clinic DHN \n",
      " \n",
      "DD:09/14/2109 \n",
      "DT:09/15/2109 \n",
      "TX:24217     :1991 \n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Record date: 2111-10-10\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "CCU JAR Transfer Note\n",
      "\n",
      "Admission Date: 10/8/11\n",
      "\n",
      "Transfer: 10/10/11\n",
      "\n",
      "Patient Name: Valdez, Harlan \n",
      "\n",
      "MRN#: 7672624\n",
      "\n",
      "Cardiologist:  Dr. Nutter\n",
      "\n",
      "PCP:  Vicente Barker\n",
      "\n",
      "\n",
      "\n",
      "CC: Chest Pain    Cath    VF arrest    RCA stenting\n",
      "\n",
      "\n",
      "\n",
      "History of Present Illness (obtained on admission):  Pt is a 48 yo male with h/o DMII, hypercholesterolemia, Bipolar d/o, and depression who began to have sub-sternal day prior to admission in car and pre-syncope + profound weakness.  This CP was minimal, but the weakness made him pull over.  He had a repeat of these symptoms day of admission.  His EKG c/w 2/2107 showed flattened T-wave in V2 and TWI in V3 and flattened T-waves in I, aVL. His trop was negative, but MB index was elevated.  Due to T-wave flattening, history and elevated index it was decided to start on heparin and ASA and take to cath lab.  \n",
      "\n",
      "\n",
      "\n",
      "Cath showed right dominant system with prox Cx 40%, LAD clear, RCA prox 70-80% lesion and ostial PDA 90%.  During final dye injection, pt had VF arrest and 2 shocks.  Pt regained puls and was in AF (new) with RVR. Pt was started on amio.  Pt then began to experience discomfort in the RVR and it was decided to intervene.  POBA was done to ostial PDA.  A first no-eluting stent was placed in prox RCA and pt had dissection and thus 2cd stent was placed.  On admission to CCU, pt still in AF with RVR (120's).  He was on amio drip, BB, loaded on plavix, ASA, lipitor, integrilin and was placed on Avandia study.  His complaint of some mild chest pain (not same as anginal pain day before) thought to be from defibrillation.\n",
      "\n",
      "\n",
      "\n",
      "Past Medical History: DMII, hyperchol, bipolar,HTN, depression (s/p ECT)\n",
      "\n",
      " \n",
      "\n",
      "Medications on admission: ASA, Lipitor 20, lopressor 50 bid, folate, norvasc 5 qd; lithium, 300 bid; depakote 500 bid; sonata 10 mg qhs, doxylamine 25 qhs, mirtazapine 45 qd \n",
      "\n",
      "\n",
      "\n",
      "Meds on Transfer: please see green sheets\n",
      "\n",
      " \n",
      "\n",
      "Medications: ASA, Lipitor 20, lopressor 50 bid, folate, norvasc 5 qd; lithium, 300 bid; depakote 500 bid; sonata 10 mg qhs, doxylamine 25 qhs, mirtazapine 45 qd \n",
      "\n",
      "\n",
      "\n",
      "Allergies:  NKDA\n",
      "\n",
      "\n",
      "\n",
      "Family History:  family h/o CAD\n",
      "\n",
      "\n",
      "\n",
      "Social History: No EtOH, no tob, no illicits\n",
      "\n",
      "\n",
      "\n",
      "Review of Systems:  per HPI\n",
      "\n",
      "\n",
      "\n",
      "Allergies:  NKDA\n",
      "\n",
      "\n",
      "\n",
      "Family History:  family h/o CAD\n",
      "\n",
      "\n",
      "\n",
      "Social History: No EtOH, no tob, no illicits\n",
      "\n",
      "\n",
      "\n",
      "Review of Systems:  per HPI\n",
      "\n",
      "\n",
      "\n",
      "CCU course + plan:\n",
      "\n",
      "1)\tCards\n",
      "\n",
      "a.\tRhythm - on night of admission patient was started on an esmolol drip as well as amio bloused and rhythm converted to NSR.  Esmolol drip as well as amio was stopped and BB was escalated and patient has remained in NSR.\n",
      "\n",
      "i.\tRamp up lopressor as tolerated by BP\n",
      "\n",
      "b.\tPump - patient has remained euvolemic and had a Echo with EF 84% and aortic stenosis\n",
      "\n",
      "c.\tIschemia - was stented x 2 to the prox RCA lesion and was on integrilin x 24hrs prior.  He was started on plavix.\n",
      "\n",
      "i.\tCont plavix, lopressor, lisinopril, lipitor, ASA\n",
      "\n",
      "\n",
      "\n",
      "2)\tPsych - patient with long history of bipolar disorder + depression.  He was on depakote, lithium and remeron as outpt.  He was seen by psychiatry here.\n",
      "\n",
      "a.\tContinue depakote and lithium (had subthereapeutic level that psych thought was likely  due to non-compliance.\n",
      "\n",
      "b.\tContinue remeron qhs\n",
      "\n",
      "c.\tF/u TSH\n",
      "\n",
      "\n",
      "\n",
      "3)\tDM - Blood sugars were originally elevated as amio drip he was originally on for AF contained dextrose. He has remained on NPH with RISS.\n",
      "\n",
      "a.\tNPH, RISS\n",
      "\n",
      "\n",
      "\n",
      "4)\tProphy - Fragmin nexium\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LABS + PE - see today's progress note\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "EKG - AFIB with RVR, diffuse t-wave flattening\n",
      "\n",
      "\n",
      "\n",
      "Impression:  48 yo male with h/o DMII, hypercholesterolemia, Bipolar d/o, and depression and CAD p/w CP and pre-sycope found to have RCA prox 70-80% lesion and ostial PDA 90% (stents to RCA and POBA to PDA).  Cath c/b VF arrest after dye load and resultant afib with RVR.\n",
      "\n",
      "\n",
      "\n",
      "Plan:  \n",
      "\n",
      "As outlined in CCU course.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Victor Shepard MD\n",
      "\n",
      "39693\n",
      "\n",
      "   \n",
      "\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Record date: 2111-12-14\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "NEUROLOGY CMF ADMISSION NOTE\n",
      "\n",
      "\n",
      "\n",
      "Name: \tVALDEZ, Harlan\n",
      "\n",
      "DOB:\t11-9-2062\n",
      "\n",
      "MR#: \t7672624\n",
      "\n",
      "Date:\t12/13/11, 9:30pm\n",
      "\n",
      "\n",
      "\n",
      "FOR DETAILS, PLEASE SEE AALIYAH IRAHETA'S NOTE\n",
      "\n",
      "\n",
      "\n",
      "ID/CC: 49yoRHM w/ PMH signif for CAD, Afib, DM, Bipolar, who presents w/ RLE weakness/decreased sensation x 24hrs\n",
      "\n",
      "\n",
      "\n",
      "HPI: 49yoRHM w/ PMH signif for CAD, Afib, DM, Bipolar, who was in USOH until 10d ago, when had weakness in his L arm.  Thought this was 2/2 sleeping on it.  Involved whole arm from shoulder down.  Was still doing his ADL's but felt like the arm was slightly weaker, took 4-5 days to get back to normal.  \n",
      "\n",
      "\n",
      "\n",
      "Then, 12/12/11, was eating dinner w/ a friend, got up to go to BR, found he had RLE weakness/stiffness.  Noticed it was hard to climb stairs.  Went to sleep    woke up at 2am    nearly fell 2/2 weakness in his leg.  In addition, has sensory loss in RLE, esp foot - felt    cold and dead.     The sensory loss was worst distally, but extended up to his thigh.  Never had trouble speaking or understanding others, did not have a facial droop, no problems w/ his RUE.  Stayed in bed until am, when he called his PCP, who told him to come to ED.  \n",
      "\n",
      "\n",
      "\n",
      "Of note, in Oct-Nov 2111, had cardiac cath x 2.  Had NSTEMI on Oct 8, 2111    taken to cardiac cath    cath showed significant RCA disease and 40% prox LCx    c/b Vfib needing defib    stent placed for stenotic RCA lesion, c/b dissection needing 2nd stent placed.  Post cath had Afib requiring amiodarone.  Then had subsequent cath Nov 1 after an episode of CP, stents patent, other vessels stable.  After his inpt cardiac hospitalization, was admitted to psych for 1 wk for suicidality/depression.  \n",
      "\n",
      "\n",
      "\n",
      "Previously, in spring 2110, had L eye visual disturbance    nearly blind    went to GHIC where was dx'ed w/ retinal venous occlusion, treated w/ cortisone and laser surgery, w/ mild improvement in vision (now blurred in that eye).\n",
      "\n",
      "\n",
      "\n",
      "No HA, no tinnitus, no vertigo.  No blurry vision except in L eye from venous occlusion, no diplopia.  No problems w/ speech.\n",
      "\n",
      "\n",
      "\n",
      "PMH: \n",
      "\n",
      "DM - insulin x years \n",
      "\n",
      "CAD s/p NSTEMI as above\n",
      "\n",
      "Bipolar disorder - on lithium and depakote, has required inpt hospitalization and ECT in past\n",
      "\n",
      "Afib as above\n",
      "\n",
      "Hyperchol\n",
      "\n",
      "\n",
      "\n",
      "MEDS: \n",
      "\n",
      "Insulin 70/30  22 units bid\n",
      "\n",
      "Asa 81\n",
      "\n",
      "Plavix 75\n",
      "\n",
      "Lithium ? dose (600 bid on prior note)\n",
      "\n",
      "Norvasc ? dose (5 on prior note)\n",
      "\n",
      "Mirtazapine ? dose (45 on prior note)\n",
      "\n",
      "Naltrexone \n",
      "\n",
      "Nexium (20 on prior note)\n",
      "\n",
      "Lipitor (40 on prior note)\n",
      "\n",
      "Cozaar ? dose\n",
      "\n",
      "Depakote ? dose (500 bid on prior note)\n",
      "\n",
      "(Lopressor 75 po q8 per prior notes)\n",
      "\n",
      "Folate\n",
      "\n",
      "\t    \n",
      "\n",
      "ALL: Lisinopril    cough\n",
      "\n",
      "\n",
      "\n",
      "SH:  \tTob:\toccas cigar\tEtOH: 0 (used to have EtOH problems)       IVDA:      0\n",
      "\n",
      "\tLives w/ 17yo son.  Has 13yo daughter who lives w/ his sister.  Widower x 3yrs.  \n",
      "\n",
      "\n",
      "\n",
      "FH:\tMom w/ PM at age 50, died of MI at 71.  Father w/ EtOH, HTN.  Sister w/ 4 miscarriages.  \n",
      "\n",
      "\n",
      "\n",
      "VS:  \t129/80\t\t89\t20\t97% on RA\n",
      "\n",
      "General:\tWNWD, NAD\n",
      "\n",
      "HEENT:\tNC/AT.  No scleral icterus.  MMM.  OP benign.  \n",
      "\n",
      "Neck:\tSupple, no carotid bruits.  \n",
      "\n",
      "CV:\t\tRRR S1, S2.  II-III/VI sys murmur best at RUSB rad to clav and neck. ? second murmur at axilla systolic as well vs. Galiverdin's sign.\n",
      "\n",
      "Resp:\tCTAB.  No r/w/r\n",
      "\n",
      "Abd:\t\t+BS.    Soft/NT/ND.\n",
      "\n",
      "Ext:\t\tNo C/C/E, DP 2+ bilat.  \n",
      "\n",
      "Skin:\t\tNo rashes, intact.  \n",
      "\n",
      "\n",
      "\n",
      "Neuro:\n",
      "\n",
      "MS:\tConversationally intact.\n",
      "\n",
      "\n",
      "\n",
      "CN: \tII,III- Pupils 5mm, round , reactive to light to 3mm; visual field full to confrontation; optic discs sharp\n",
      "\n",
      "III,IV,VI-extraocular movements full, w/o nystagmus, L eyelid is slightly weaker longstanding since L eye problem\n",
      "\n",
      "V--sensation to LT and pin-prick intact bilaterally\n",
      "\n",
      "VII-facial expression muscles symmetric without weakness\n",
      "\n",
      "IX,X--palate elevates symmetrically\n",
      "\n",
      "XI--SCMs 5/5\n",
      "\n",
      "XII--tongue protrudes midline\n",
      "\n",
      "\n",
      "\n",
      "Motor:\tnormal bulk and tone; no tremor. No pronator drift. \n",
      "\n",
      "\n",
      "\n",
      "\tDelt\tElF\tElE\tWrE\tFE\tIO\tHpF\tKnE\tKnF\tDors\tPlan\tEHL\t\n",
      "\n",
      "L\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t\n",
      "\n",
      "R\t5\t5\t5\t5\t5\t5\t5\t5\t5\t4+\t5\t5\t\n",
      "\n",
      "\n",
      "\n",
      "Sensory: \tendorses a difference in sensation to LT and temp RLE vs. LLE.  Zone of difference (feels colder) is most pronounced R lateral calf area, not a particular dermatomal distribution, also w/ toe position sense mildly decreased R great toe.  Mild vibratory loss to ankles bilat symmetrical.   \n",
      "\n",
      "Reflex:\t\n",
      "\n",
      "\tBic\tTric\tBra\tHoff\tPat\tAnk\tToes\t\n",
      "\n",
      "L\t2\t2\t2\tNeg\t2\t2\tDown\t\n",
      "\n",
      "R\t2+\t2\t2+\tNeg\t3\t2\tUp?\t\n",
      "\n",
      "\n",
      "\n",
      "Coord:\tno dysmetria on finger-nose-finger or heel-knee-shin\n",
      "\n",
      "Gait:\tfavors L leg slightly when walking\n",
      "\n",
      "\n",
      "\n",
      "Romberg:  normal \n",
      "\n",
      "\n",
      "\n",
      "LABS/STUDIES:\n",
      "\n",
      "Chemistry\n",
      "\n",
      "  Lytes/Renal/Glucose\n",
      "\n",
      "    Sodium                 136   135-145 mmol/L     12/13/11 18:35     133(L) 12/13/11 09:43\n",
      "\n",
      "    Potassium              3.6   3.4-4.8 mmol/L     12/13/11 18:35     4.9(H) 10/31/11 12:55\n",
      "\n",
      "    Chloride               109H  100-108 mmol/L     12/13/11 18:35     109(H) 12/13/11 18:35\n",
      "\n",
      "    Carbon Dioxide        27.0   23.0-31.9 mmol/L   12/13/11 18:35    22.9(L) 12/10/11 20:33\n",
      "\n",
      "    BUN                     11   8-25 mg/dl         12/13/11 18:35\n",
      "\n",
      "    Creatinine             1.0   0.6-1.5 mg/dl      12/13/11 18:35\n",
      "\n",
      "    Glucose                216H  70-110 mg/dl       12/13/11 18:35     216(H) 12/13/11 18:35\n",
      "\n",
      "  General Chemistries\n",
      "\n",
      "    Calcium                9.4   8.5-10.5 mg/dl     12/13/11 10:40     8.3(L) 10/10/11 06:15\n",
      "\n",
      "    Phosphorus             3.2   2.6-4.5 mg/dl      12/13/11 10:40     2.4(L) 11/02/11 15:10\n",
      "\n",
      "    Magnesium              1.6   1.4-2.0 meq/L      12/13/11 10:40\n",
      "\n",
      "  Lipid Tests\n",
      "\n",
      "    Cholesterol            173   mg/dl              12/10/11 20:33     228(H) 09/03/07 10:46\n",
      "\n",
      "    Triglycerides          547H  40-150 mg/dl       12/10/11 20:33     547(H) 12/10/11 20:33\n",
      "\n",
      "    HDL Cholesterol         25L  35-100 mg/dl       12/10/11 20:33      25(L) 12/10/11 20:33\n",
      "\n",
      "    LDL Cholesterol         --   mg/dl              12/10/11 20:33\n",
      "\n",
      "    Chol/HDL Ratio         6.9                      12/10/11 20:33\n",
      "\n",
      "  Chemistry Miscellaneous\n",
      "\n",
      "    Calc Mean Bld...       254   mg%                12/12/11 10:34\n",
      "\n",
      "    Chemistry Com...  see detail                    05/09/08 21:58\n",
      "\n",
      "    Hemoglobin A1C       10.20H  3.80-6.40 %        12/12/11 10:34   10.20(H) 12/12/11 10:34\n",
      "\n",
      "Hematology\n",
      "\n",
      "  Complete Blood Count\n",
      "\n",
      "    WBC                    6.1   4.5-11.0 th/cmm    12/13/11 09:51    11.1(H) 10/08/11 20:16\n",
      "\n",
      "    RBC                   4.51   4.50-5.90 mil/cm   12/13/11 09:51    4.37(L) 11/03/11 11:15\n",
      "\n",
      "    Hgb                   13.7   13.5-17.5 gm/dl    12/13/11 09:51    13.1(L) 11/01/11 04:52\n",
      "\n",
      "    HCT                   39.4L  41.0-53.0 %        12/13/11 09:51    39.4(L) 12/13/11 09:51\n",
      "\n",
      "    MCV                     87   80-100 fl          12/13/11 09:51\n",
      "\n",
      "    MCH                   30.4   26.0-34.0 pg/rbc   12/13/11 09:51\n",
      "\n",
      "    MCHC                  34.9   31.0-37.0 g/dl     12/13/11 09:51\n",
      "\n",
      "    PLT                    210   150-350 th/cumm    12/13/11 09:51\n",
      "\n",
      "    RDW                   13.5   11.5-14.5 %        12/13/11 09:51\n",
      "\n",
      "  Other Hematology\n",
      "\n",
      "    ESR                     14   0-17 mm/hr         12/13/11 19:51\n",
      "\n",
      "Urinalysis\tNegative\n",
      "\n",
      "Therapeutic Drugs\n",
      "\n",
      "  Therapeutic Drug Monitoring\n",
      "\n",
      "    Lithium              <0.10L  0.50-1.50 mmol/L   12/13/11 20:40   <0.10(L) 12/13/11 20:40\n",
      "\n",
      "\n",
      "\n",
      "MRI brain: Acute/subacute infarcts (DWI bright/ADC dark/FLAIR bright) in L cerebellum (punctate) and R precentral gyrus (small elliptical area).  \n",
      "\n",
      "\n",
      "\n",
      "CT-A head/neck: has aberrant origin of R vert from CCA, both ACA's come off of L carotid, also w/ bilateral fetal PCA's and likely congenitally small vertebrobasilar vessels.  No significant focal stenoses or atheromatous calcifications.  \n",
      "\n",
      "\n",
      "\n",
      "EKG: pending\n",
      "\n",
      "\n",
      "\n",
      "MRI L/S spine: negative\n",
      "\n",
      "\n",
      "\n",
      "IMPRESSION:\n",
      "\n",
      "49yoRHM w/ PMH signif for CAD, DM, Bipolar disorder, afib, s/p recent cardiac cath who presents w/ LUE weakness 10d prior to admission resolving after 4-5 days, and RLE weakness?/sensory deficit? Imaging reveals R precentral gyrus small infarct, L cerebellar infarct, no significant vessel stenoses.  Neuro exam w/ brisker reflexes on R, equivocal RLE weakness, R sensory sx, ? R upgoing toe.  Clinical picture and imaging are not consistent.  Unclear if pt is a poor historian and current sx are non-objective sensory findings and meaningful event was LUE weakness 4-5d ago.\n",
      "\n",
      "NEURO: stroke w/u including TTE/Holter, lipids/lipoprotein/homocysteine.  \n",
      "\n",
      "--Will also send hypercoag w/u (including hypercoag panel, PT20210, Factor V Leiden, APLA, lupus anticoagulant) given hx of retinal venous thrombus and young age.\n",
      "\n",
      "--Will also send BCx2 given recent cardiac cath, although ESR wnl reassuring re ? of endocarditis.\n",
      "\n",
      "--Will check A1c re ? of adequate DM control.\n",
      "\n",
      "--Given psych hx, will check tox screen and LFT's.\n",
      "\n",
      "--Unclear if afib was only in context of post-cath, post Vfib.  Will look for LAE, holter abnl.  Could make a case to anti-coagulate regardless as has had documented afib.  \n",
      "\n",
      "CV: hold anti-htn meds now.  Continue lipitor at outpt dose.  Allow SBP up to 180.\n",
      "\n",
      "PSYCH: continue w/ depakote and lithium.  Mood is ok now, but will need to be monitored.\n",
      "\n",
      "FEN: no IVF, ada 1800 low chol/low fat diet.  \n",
      "\n",
      "ENDO: NPH 20 bid for now, titrate up as needed, RISS.  Checking A1c.\n",
      "\n",
      "PPX: put on sc fragmin, nexium.  Pneumoboots.  \n",
      "\n",
      "\n",
      "\n",
      "Anna V. Wendy-Bird, MD\n",
      "\n",
      "HPC Neuro Resident #48600\n",
      "\n",
      "Case discussed w/ Vern Snow, senior resident.  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for description in root.iter('TEXT'):\n",
    "    print(description.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "See if there are gender identifying words from each sentence and label them as 0-male 1-female.\n",
    "Used whitespaces to check individual words.\n",
    "Used regular expression to recognize sentences and replaced multiple \\n to a whitespace.\n",
    "(Lots of \\n due to xml format file characteristics.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "filenames = glob.glob(\"./train/[0-9][0-9][0-9].xml\")  # change the pattern to match your case\n",
    "lines = []\n",
    "temp_label = 0\n",
    "total_labels = []\n",
    "for filename in filenames:\n",
    "\n",
    "    with open(filename, 'r', encoding=\"utf-8\") as content:\n",
    "\n",
    "        tree = ET.parse(content)\n",
    "#        lines.append(ET.tostring(tree.getroot(), encoding='utf-8', method='text'))\n",
    "        for description in root.iter('TEXT'):\n",
    "            ##use regular expression to replace multiple tabs with a whitespace\n",
    "            ##xml format uses multiple '\\n's to visualize rows or columns\n",
    "            ##use regular expression to only retrieve sentences\n",
    "            temp =re.sub(' [\\n]{2,}',' ',description.text)\n",
    "            sentence = re.findall('[0-9]*[A-Z][^.!?]+[.!?][\\n]',temp) ##find sentences\n",
    "            for sen in sentence:\n",
    "                ##check if sentence has gender specific word \n",
    "                ##for ex, the patient - she/he, his/her report, a female/male patient\n",
    "                ##if not, consider the sentence is from the same report as previous one\n",
    "                if ' She ' in (' ' + sen + ' '):\n",
    "                    temp_label = 1\n",
    "                elif ' she ' in (' ' + sen + ' '):\n",
    "                    temp_label = 1\n",
    "                elif ' her ' in (' ' + sen + ' '):\n",
    "                    temp_label = 1\n",
    "                elif ' Her ' in (' ' + sen + ' '):\n",
    "                    temp_label = 1\n",
    "                elif ' female ' in (' ' + sen + ' '):\n",
    "                    temp_label = 1\n",
    "                elif ' He ' in (' ' + sen + ' '):\n",
    "                    temp_label = 0\n",
    "                elif ' he ' in (' ' + sen + ' '):\n",
    "                    temp_label = 0\n",
    "                elif ' his ' in (' ' + sen + ' '):\n",
    "                    temp_label = 0\n",
    "                elif ' His ' in (' ' + sen + ' '):\n",
    "                    temp_label = 0\n",
    "                elif ' male ' in (' ' + sen + ' '):\n",
    "                    temp_label = 0\n",
    "                else:\n",
    "                    temp_label = temp_label\n",
    "                total_labels.append(temp_label)\n",
    "            lines.extend(sentence)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He is a set designer at Columbia Pictures.\\n',\n",
       " 'Diagnosis:  Left ankle fracture.\\n',\n",
       " 'This is a brief addendum to the medical record.\\n',\n",
       " 'The patient has no chest pain at the time of evaluation in the emergency department and no shortness of breath.\\n',\n",
       " 'REVIEW OF SYSTEMS:  As indicated and otherwise negative.\\n',\n",
       " 'PAST MEDICAL HISTORY:  As indicated in the chart.\\n',\n",
       " 'SOCIAL HISTORY AND FAMILY HISTORY:  As indicated in the chart.\\n',\n",
       " 'A CT is pending at the time of this dictation.\\n',\n",
       " 'His complaint of some mild chest pain (not same as anginal pain day before) thought to be from defibrillation.\\n',\n",
       " 'Esmolol drip as well as amio was stopped and BB was escalated and patient has remained in NSR.\\n']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_lines = lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = int(len(total_lines)*0.7)\n",
    "train_lines = total_lines[:train_ratio]\n",
    "train_label = total_labels[:train_ratio]\n",
    "valid_lines = total_lines[train_ratio:]\n",
    "valid_label = total_labels[train_ratio:]\n",
    "train_set = np.column_stack((train_lines, train_label))\n",
    "valid_set = np.column_stack((valid_lines, valid_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(train_set)\n",
    "train_data.to_csv('./train.txt', sep='\\t', index=False)\n",
    "valid_data = pd.DataFrame(valid_set)\n",
    "valid_data.to_csv('./valid.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob.glob(\"./test/[0-9][0-9][0-9].xml\")  # change the pattern to match your case\n",
    "lines = []\n",
    "temp_label = 0\n",
    "total_labels = []\n",
    "for filename in filenames:\n",
    "\n",
    "    with open(filename, 'r', encoding=\"utf-8\") as content:\n",
    "\n",
    "        tree = ET.parse(content)\n",
    "#        lines.append(ET.tostring(tree.getroot(), encoding='utf-8', method='text'))\n",
    "\n",
    "        for description in root.iter('TEXT'):\n",
    "            ##use regular expression to replace multiple tabs with a whitespace\n",
    "            ##xml format uses multiple '\\n's to visualize rows or columns\n",
    "            ##use regular expression to only retrieve sentences\n",
    "            temp =re.sub(' [\\n]{2,}',' ',description.text)\n",
    "            sentence = re.findall('[0-9]*[A-Z][^.!?]+[.!?][\\n]',temp) ##find sentences\n",
    "            ##check if sentence has gender specific word \n",
    "            ##for ex, the patient - she/he, his/her report, a female/male patient\n",
    "            ##if not, consider the sentence is from the same report as previous one\n",
    "            ##us below format of if statement to check for individual words\n",
    "            for sen in sentence:\n",
    "                if ' She ' in (' ' + sen + ' '):\n",
    "                    temp_label = 1\n",
    "                elif ' she ' in (' ' + sen + ' '):\n",
    "                    temp_label = 1\n",
    "                elif ' her ' in (' ' + sen + ' '):\n",
    "                    temp_label = 1\n",
    "                elif ' Her ' in (' ' + sen + ' '):\n",
    "                    temp_label = 1\n",
    "                elif ' female ' in (' ' + sen + ' '):\n",
    "                    temp_label = 1\n",
    "                elif ' He ' in (' ' + sen + ' '):\n",
    "                    temp_label = 0\n",
    "                elif ' he ' in (' ' + sen + ' '):\n",
    "                    temp_label = 0\n",
    "                elif ' his ' in (' ' + sen + ' '):\n",
    "                    temp_label = 0\n",
    "                elif ' His ' in (' ' + sen + ' '):\n",
    "                    temp_label = 0\n",
    "                elif ' male ' in (' ' + sen + ' '):\n",
    "                    temp_label = 0\n",
    "                else:\n",
    "                    temp_label = temp_label\n",
    "                total_labels.append(temp_label)\n",
    "            lines.extend(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He is a set designer at Columbia Pictures.\\n',\n",
       " 'Diagnosis:  Left ankle fracture.\\n',\n",
       " 'This is a brief addendum to the medical record.\\n',\n",
       " 'The patient has no chest pain at the time of evaluation in the emergency department and no shortness of breath.\\n',\n",
       " 'REVIEW OF SYSTEMS:  As indicated and otherwise negative.\\n',\n",
       " 'PAST MEDICAL HISTORY:  As indicated in the chart.\\n',\n",
       " 'SOCIAL HISTORY AND FAMILY HISTORY:  As indicated in the chart.\\n',\n",
       " 'A CT is pending at the time of this dictation.\\n',\n",
       " 'His complaint of some mild chest pain (not same as anginal pain day before) thought to be from defibrillation.\\n',\n",
       " 'Esmolol drip as well as amio was stopped and BB was escalated and patient has remained in NSR.\\n']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lines = lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = np.column_stack((test_lines,total_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.DataFrame(test_set)\n",
    "test_data.to_csv('./test.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Piece Tokenizer\n",
    "### Word Piece embedding\n",
    "#### Convert text to token pieces using tokenizer based on vocab\n",
    "#### Word embeddings are a type of word representation that allows words with similar meaning to have a similar representation.\n",
    "\n",
    "example:\n",
    "\n",
    "Input Text: the man jumped up, put his basket on philammon's head  \n",
    "Word piece: [\"the\", \"man\", \"jump\", \"##ed\", \"up\", \"put\", \"his\", \"basket\", \"on\", \"phil\", \"##am\", \"##mon\",\"'\", \"s\", \"head\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import collections\n",
    "import unicodedata\n",
    "import six\n",
    "\n",
    "\n",
    "def convert_to_unicode(text):\n",
    "    \"\"\"transform not unicode file to unicode file\"\"\"\n",
    "    if six.PY3:\n",
    "        if isinstance(text, str):\n",
    "            return text\n",
    "        elif isinstance(text, bytes):\n",
    "            return text.decode(\"utf-8\", \"ignore\")\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n",
    "    elif six.PY2:\n",
    "        if isinstance(text, str):\n",
    "            return text.decode(\"utf-8\", \"ignore\")\n",
    "        elif isinstance(text, unicode):\n",
    "            return text\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n",
    "    else:\n",
    "        raise ValueError(\"Not running on Python2 or Python 3?\")\n",
    "\n",
    "def load_vocab(vocab_file):\n",
    "    \"\"\"read vocabs from vocab.txt of BioBERT pretraining model \n",
    "       make dictionary -> key: word, value: unique index \"\"\"\n",
    "    vocab = collections.OrderedDict()\n",
    "    index = 0\n",
    "    with tf.gfile.GFile(vocab_file, \"r\") as reader:\n",
    "        while True:\n",
    "            token = convert_to_unicode(reader.readline())\n",
    "            if not token:\n",
    "                break\n",
    "            token = token.strip()\n",
    "            vocab[token] = index\n",
    "            index += 1\n",
    "    return vocab\n",
    "\n",
    "def convert_by_vocab(vocab, items):\n",
    "    \"\"\"ge input of token sequence and use vocab dictionary to return tokens' index sequence\"\"\"\n",
    "    output = []\n",
    "    for item in items:\n",
    "        output.append(vocab[item])\n",
    "    return output\n",
    "\n",
    "def whitespace_tokenize(text):\n",
    "    \"\"\"get rid of white space and separate plural tokens\"\"\"\n",
    "    text = text.strip()\n",
    "    if not text:\n",
    "        return []\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "class FullTokenizer(object):\n",
    "    \"\"\"end-to-end tokenziation.\"\"\"\n",
    "    def __init__(self, vocab_file, do_lower_case=True):\n",
    "        self.vocab = load_vocab(vocab_file)\n",
    "        self.inv_vocab = {v: k for k, v in self.vocab.items()}\n",
    "        self.basic_tokenizer = BasicTokenizer(do_lower_case=do_lower_case)\n",
    "        self.wordpiece_tokenizer = WordpieceTokenizer(vocab=self.vocab)\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        split_tokens = []\n",
    "        for token in self.basic_tokenizer.tokenize(text):\n",
    "            for sub_token in self.wordpiece_tokenizer.tokenize(token):\n",
    "                split_tokens.append(sub_token)\n",
    "\n",
    "        return split_tokens\n",
    "\n",
    "    def convert_tokens_to_ids(self, tokens):\n",
    "        return convert_by_vocab(self.vocab, tokens)\n",
    "\n",
    "    def convert_ids_to_tokens(self, ids):\n",
    "        return convert_by_vocab(self.inv_vocab, ids)\n",
    "\n",
    "class BasicTokenizer(object):\n",
    "    \"\"\"basic tokenization\"\"\"\n",
    "\n",
    "    def __init__(self, do_lower_case=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          do_lower_case: will you lower case todkens?(True/False)\n",
    "        \"\"\"\n",
    "        self.do_lower_case = do_lower_case\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        \"\"\"Tokenizes a piece of text.\"\"\"\n",
    "        text = convert_to_unicode(text)\n",
    "        text = self._clean_text(text)\n",
    "\n",
    "        orig_tokens = whitespace_tokenize(text)\n",
    "        split_tokens = []\n",
    "        for token in orig_tokens:\n",
    "            if self.do_lower_case:\n",
    "                token = token.lower()\n",
    "                token = self._run_strip_accents(token)\n",
    "            split_tokens.extend(self._run_split_on_punc(token))\n",
    "\n",
    "        output_tokens = whitespace_tokenize(\" \".join(split_tokens))\n",
    "        return output_tokens\n",
    "\n",
    "    def _run_strip_accents(self, text):\n",
    "        \"\"\"Strips accents from a piece of text.\"\"\"\n",
    "        text = unicodedata.normalize(\"NFD\", text)\n",
    "        output = []\n",
    "        for char in text:\n",
    "            cat = unicodedata.category(char)\n",
    "            if cat == \"Mn\":\n",
    "                continue\n",
    "            output.append(char)\n",
    "        return \"\".join(output)\n",
    "\n",
    "    def _run_split_on_punc(self, text):\n",
    "        \"\"\"Splits punctuation on a piece of text.\"\"\"\n",
    "        chars = list(text)\n",
    "        i = 0\n",
    "        start_new_word = True\n",
    "        output = []\n",
    "        while i < len(chars):\n",
    "            char = chars[i]\n",
    "            if _is_punctuation(char):\n",
    "                output.append([char])\n",
    "                start_new_word = True\n",
    "            else:\n",
    "                if start_new_word:\n",
    "                    output.append([])\n",
    "                start_new_word = False\n",
    "                output[-1].append(char)\n",
    "            i += 1\n",
    "        return [\"\".join(x) for x in output]\n",
    "\n",
    "\n",
    "    def _clean_text(self, text):\n",
    "        \"\"\"Performs invalid character removal and whitespace cleanup on text.\"\"\"\n",
    "        output = []\n",
    "        for char in text:\n",
    "            cp = ord(char)\n",
    "            if cp == 0 or cp == 0xfffd or _is_control(char):\n",
    "                continue\n",
    "            if _is_whitespace(char):\n",
    "                output.append(\" \")\n",
    "            else:\n",
    "                output.append(char)\n",
    "        return \"\".join(output)\n",
    "\n",
    "\n",
    "class WordpieceTokenizer(object):\n",
    "    \"\"\"WordPiece tokenziation.\"\"\"\n",
    "\n",
    "    def __init__(self, vocab, unk_token=\"[UNK]\", max_input_chars_per_word=200):\n",
    "        self.vocab = vocab\n",
    "        self.unk_token = unk_token\n",
    "        self.max_input_chars_per_word = max_input_chars_per_word\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        \"\"\"\n",
    "\n",
    "        For example:\n",
    "          input = \"unaffable\"\n",
    "          output = [\"un\", \"##aff\", \"##able\"]\n",
    "\n",
    "        Args:\n",
    "          text: A single token or whitespace separated tokens. This should have\n",
    "            already been passed through `BasicTokenizer.\n",
    "\n",
    "        Returns:\n",
    "          A list of wordpiece tokens.\n",
    "        \"\"\"\n",
    "\n",
    "        text = convert_to_unicode(text)\n",
    "\n",
    "        output_tokens = []\n",
    "        for token in whitespace_tokenize(text):\n",
    "            chars = list(token)\n",
    "            if len(chars) > self.max_input_chars_per_word:\n",
    "                output_tokens.append(self.unk_token)\n",
    "                continue\n",
    "\n",
    "            is_bad = False\n",
    "            start = 0\n",
    "            sub_tokens = []\n",
    "            while start < len(chars):\n",
    "                end = len(chars)\n",
    "                cur_substr = None\n",
    "                while start < end:\n",
    "                    substr = \"\".join(chars[start:end])\n",
    "                    if start > 0:\n",
    "                        substr = \"##\" + substr\n",
    "                    if substr in self.vocab:\n",
    "                        cur_substr = substr\n",
    "                        break\n",
    "                    end -= 1\n",
    "                if cur_substr is None:\n",
    "                    is_bad = True\n",
    "                    break\n",
    "                sub_tokens.append(cur_substr)\n",
    "                start = end\n",
    "\n",
    "            if is_bad:\n",
    "                output_tokens.append(self.unk_token)\n",
    "            else:\n",
    "                output_tokens.extend(sub_tokens)\n",
    "        return output_tokens\n",
    "    \n",
    "def _is_whitespace(char):\n",
    "    \"\"\"check if input is white space\"\"\"\n",
    "    # \\t, \\n, and \\r are technically contorl characters but we treat them\n",
    "    # as whitespace since they are generally considered as such.\n",
    "    if char == \" \" or char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n",
    "        return True\n",
    "    cat = unicodedata.category(char)\n",
    "    if cat == \"Zs\":\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "def _is_control(char):\n",
    "    \"\"\"check if input is control character\"\"\"\n",
    "    # These are technically control characters but we count them as whitespace\n",
    "    # characters.\n",
    "    if char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n",
    "        return False\n",
    "    cat = unicodedata.category(char)\n",
    "    if cat.startswith(\"C\"):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def _is_punctuation(char):\n",
    "    \"\"\"check if input character is punctuation character\"\"\"\n",
    "    cp = ord(char)\n",
    "    # We treat all non-letter/number ASCII as punctuation.\n",
    "    # Characters such as \"^\", \"$\", and \"`\" are not in the Unicode\n",
    "    # Punctuation class but we treat them as punctuation anyways, for\n",
    "    # consistency.\n",
    "    if ((cp >= 33 and cp <= 47) or (cp >= 58 and cp <= 64) or\n",
    "        (cp >= 91 and cp <= 96) or (cp >= 123 and cp <= 126)):\n",
    "        return True\n",
    "    cat = unicodedata.category(char)\n",
    "    if cat.startswith(\"P\"):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './models2'\n",
    "vocab = model_path+'/vocab.txt'\n",
    "\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
    "\n",
    "max_seq_length= 128\n",
    "tokenizer = BertTokenizer.from_pretrained(vocab, do_lower_case=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get final input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import spacy\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "import en_core_web_lg\n",
    "nlp = en_core_web_lg.load()\n",
    "\n",
    "def convert_single_example(text, max_seq_length, tokenizer, seg_id): \n",
    "    \n",
    "    textlist = text[0].split() # sentenceA in words\n",
    "    label = [text[1]]\n",
    "    # word piece tokenize them and put them in tokensA and tokensB\n",
    "    tokens = []\n",
    "    for word in textlist:\n",
    "        token = tokenizer.tokenize(word)\n",
    "        tokens.extend(token)\n",
    "        \n",
    "    \"\"\"model gets an input for max_seq_length of token\n",
    "       input: [CLS] tokens [SEP]\n",
    "       so, (the number of sentence tokens) <= (max_seq_length-2)\n",
    "       \n",
    "       if it's longer,\n",
    "       remove tokens with the length of (total number of tokens)-(max_seq_length-2).\"\"\"\n",
    "    if len(tokens) > max_seq_length-2:\n",
    "        cut_len = len(tokens)-(max_seq_length-2)\n",
    "        len_tokens = math.ceil(len(tokens)/(len(tokens)*cut_len))\n",
    "        tokens = tokens[len_tokens:]\n",
    "            \n",
    "        \n",
    "    # make input_ids, segment_ids -> will be used in model as inputs\n",
    "    ntokens = []\n",
    "    segment_ids = []\n",
    "    ntokens.append(\"[CLS]\") # example start token\n",
    "    segment_ids.append(0)\n",
    "    for token in tokens:\n",
    "        # add tokensA \n",
    "        ntokens.append(token)\n",
    "        segment_ids.append(seg_id)\n",
    "    ntokens.append(\"[SEP]\") # example end token\n",
    "    segment_ids.append(0)\n",
    "    \n",
    "    input_ids = tokenizer.convert_tokens_to_ids(ntokens) # convert token to matching index\n",
    " \n",
    "    # pad til max_seq_length\n",
    "    while len(input_ids) < max_seq_length:\n",
    "        input_ids.append(0)\n",
    "        segment_ids.append(0)\n",
    "        # we don't concerned about it!\n",
    "        ntokens.append(\"**NULL**\")\n",
    "        \n",
    "    input_ids = input_ids[:max_seq_length]\n",
    "    segment_ids = segment_ids[:max_seq_length]\n",
    "    \n",
    "    # errors made when the lengths of input_ids and segment_ids are not\n",
    "    # max_seq_length\n",
    "    assert len(input_ids) == max_seq_length   \n",
    "    assert len(segment_ids) == max_seq_length \n",
    "    \n",
    "    return input_ids, segment_ids, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(data_set):\n",
    "\n",
    "    result_input_ids=[]\n",
    "    result_seg_ids=[]\n",
    "    y=[]\n",
    "    seg_id = 0\n",
    "    \n",
    "    for example in data_set:\n",
    "        input_ids, segment_ids, label = convert_single_example(example, max_seq_length, tokenizer, seg_id)\n",
    "        result_input_ids.append(input_ids)\n",
    "        result_seg_ids.append(segment_ids)\n",
    "        y.append(label)\n",
    "        ## set segment id for next sentence\n",
    "        if seg_id == 0:\n",
    "            seg_id = 1\n",
    "        else:\n",
    "            seg_id = 0\n",
    "        \n",
    "    data_x = []\n",
    "    data_y = []\n",
    "    data_x.append(np.array(result_input_ids))\n",
    "    data_x.append(np.array(result_seg_ids))\n",
    "\n",
    "    data_y.append(np.array(y))\n",
    "        \n",
    "    return data_x, data_y\n",
    "\n",
    "# convert datasets to the shape of input_feature and y(label)\n",
    "train_x, train_y = data_loader(train_set)\n",
    "valid_x, valid_y = data_loader(valid_set)\n",
    "test_x, test_y = data_loader(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset's shape\n",
      "(2, 3959, 128)\n",
      "(1, 3959, 1)\n",
      "---------------\n",
      "valid dataset' shape\n",
      "(2, 1697, 128)\n",
      "(1, 1697, 1)\n",
      "---------------\n",
      "test dataset' shape\n",
      "(2, 2408, 128)\n",
      "(1, 2408, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"train dataset's shape\")\n",
    "print(np.array(train_x).shape)\n",
    "print(np.array(train_y).shape)\n",
    "print(\"-\"*15)\n",
    "print(\"valid dataset' shape\")\n",
    "print(np.array(valid_x).shape)\n",
    "print(np.array(valid_y).shape)\n",
    "print(\"-\"*15)\n",
    "print(\"test dataset' shape\")\n",
    "print(np.array(test_x).shape)\n",
    "print(np.array(test_y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[  101,  1119,  1110, ...,     0,     0,     0],\n",
      "       [  101, 12645,   131, ...,     0,     0,     0],\n",
      "       [  101,  1142,  1110, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [  101,  1117, 12522, ...,     0,     0,     0],\n",
      "       [  101, 13936,  3702, ...,     0,     0,     0],\n",
      "       [  101,  1119,  1108, ...,     0,     0,     0]]), array([[0, 1, 1, ..., 0, 0, 0],\n",
      "       [0, 1, 1, ..., 0, 0, 0],\n",
      "       [0, 1, 1, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 1, 1, ..., 0, 0, 0],\n",
      "       [0, 1, 1, ..., 0, 0, 0],\n",
      "       [0, 1, 1, ..., 0, 0, 0]])]\n",
      "[array([['0'],\n",
      "       ['0'],\n",
      "       ['0'],\n",
      "       ...,\n",
      "       ['0'],\n",
      "       ['0'],\n",
      "       ['0']], dtype='<U1')]\n"
     ]
    }
   ],
   "source": [
    "print(train_x)\n",
    "print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 128 \n",
    "BATCH_SIZE = 16\n",
    "EPOCHS=3\n",
    "LR=1e-5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained BioBERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = os.path.join(model_path, 'bert_config.json')\n",
    "checkpoint_path = os.path.join(model_path, 'model.ckpt-1000000')\n",
    "vocab_path = os.path.join(model_path, 'vocab.txt')\n",
    "\n",
    "layer_num = 12\n",
    "model = load_trained_model_from_checkpoint(\n",
    "    config_path,\n",
    "    checkpoint_path,\n",
    "    training= False,\n",
    "    trainable=True,\n",
    "    seq_len=SEQ_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_finetuning_model(model):\n",
    "    inputs = model.inputs[:2] #two inputs of segment, token \n",
    "    dense = model.output # bioBERT model's output sensor\n",
    "    out = keras.layers.Dropout(0.2)(dense)\n",
    "    \n",
    "    first_tensors = Lambda(lambda x : x[:, 0, :])(out) # only used by [CLS] tensor\n",
    "    hidden_size = int(first_tensors.shape[-1])\n",
    "    pooled_output = keras.layers.Dense(hidden_size, activation='tanh')(first_tensors)\n",
    "    output_layer=keras.layers.Dense(1, activation='sigmoid')(pooled_output) # take output of bioBERT pretraining model as an input\n",
    "    \n",
    "    model = keras.models.Model(inputs, output_layer) # final model that takes Gender specification layer as a final layer\n",
    "\n",
    "    # callback = StopTrainingClassComplete()\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = get_bert_finetuning_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (TokenEmbedding [(None, 128, 768), ( 22268928    Input-Token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, 128, 768)     1536        Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, 128, 768)     0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmb (None, 128, 768)     98304       Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, 128, 768)     0           Embedding-Position[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, 128, 768)     1536        Embedding-Dropout[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     2362368     Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-1-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     0           Embedding-Norm[0][0]             \n",
      "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-1-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-1-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-1-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-2-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-2-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-2-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-2-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-2-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-3-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-2-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-3-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-3-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-3-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-3-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-4-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-3-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-4-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-4-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-4-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-4-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-5-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-4-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-5-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-5-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-5-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-5-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-6-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-5-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-6-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-6-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-6-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-6-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-7-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-6-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-7-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-7-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-7-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-7-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-8-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-7-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-8-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-8-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-8-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-8-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-9-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-8-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-9-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-9-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-9-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-9-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-9-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Dropout  (None, 128, 768)     0           Encoder-10-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Add (Add (None, 128, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
      "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-10-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-10-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-10-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Dropout  (None, 128, 768)     0           Encoder-11-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Add (Add (None, 128, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
      "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-11-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-11-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-11-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Dropout  (None, 128, 768)     0           Encoder-12-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Add (Add (None, 128, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
      "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-12-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128, 768)     0           Encoder-12-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 768)          0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 768)          590592      lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            769         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 108,016,129\n",
      "Trainable params: 108,016,129\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3959 samples, validate on 1697 samples\n",
      "Epoch 1/3\n",
      "3959/3959 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.6878\n",
      "Epoch 00001: saving model to ./models2/model.ckpt-1000000\n",
      "3959/3959 [==============================] - 2349s 593ms/sample - loss: 0.6937 - accuracy: 0.6878 - val_loss: 0.6084 - val_accuracy: 0.7130\n",
      "Epoch 2/3\n",
      "3959/3959 [==============================] - ETA: 0s - loss: 0.6166 - accuracy: 0.7067\n",
      "Epoch 00002: saving model to ./models2/model.ckpt-1000000\n",
      "3959/3959 [==============================] - 1911s 483ms/sample - loss: 0.6166 - accuracy: 0.7067 - val_loss: 0.6020 - val_accuracy: 0.7130\n",
      "Epoch 3/3\n",
      "3959/3959 [==============================] - ETA: 0s - loss: 0.6085 - accuracy: 0.7131\n",
      "Epoch 00003: saving model to ./models2/model.ckpt-1000000\n",
      "3959/3959 [==============================] - 1939s 490ms/sample - loss: 0.6085 - accuracy: 0.7131 - val_loss: 0.6234 - val_accuracy: 0.7130\n"
     ]
    }
   ],
   "source": [
    "checkpointName = os.path.join(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpointName,\n",
    "                                                     save_weights_only=True,\n",
    "                                                     verbose=1)\n",
    "history = bert_model.fit(\n",
    "        train_x,\n",
    "        train_y,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=(valid_x, valid_y),\n",
    "        verbose=1,\n",
    "        callbacks=[cp_callback],\n",
    "        batch_size = BATCH_SIZE\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model and get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array(bert_model.predict(test_x)) # use fine-tuned bioBERT model to predict on test set\n",
    "preds = np.reshape(preds, [-1]) # [[pred1],[pred2],[pred3],..] -> [pred1,pred2,pred3,..]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for pred in preds:\n",
    "    pred_temp = int(round(pred))\n",
    "    if pred_temp >= 0.5:\n",
    "        predictions.append(1) \n",
    "    else:\n",
    "        predictions.append(0)# pred value would be 0 (male) or 1 (female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2408"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_labels = total_labels # [label1, label2, label3, ...], which are actual values with total_labels from above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show performance scores\n",
    "#### accuracy - check how many predictions are made correctly\n",
    "#### precision - check how many female specificied predictions are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"accuracy: %0.4f\" %accuracy_score(actual_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision-score: 0.3571\n",
      "recall-score: 0.5000\n",
      "f1-score: 0.4167\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"precision-score: %0.4f\" % precision_score(actual_labels, predictions, average='macro'))\n",
    "print(\"recall-score: %0.4f\" % recall_score(actual_labels, predictions, average='macro'))\n",
    "print(\"f1-score: %0.4f\" % f1_score(actual_labels, predictions, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result \n",
    "### It shows gender bias. Predictions on male are made more accurately than predictions on female."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
